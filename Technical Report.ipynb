{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical Report\n",
    "Kyle Pavey and Adam Lee  \n",
    "## Introduction:\n",
    "In our project we utilized the Spotify API to grab attributes of a\n",
    "song and predict its popularity. \n",
    "We classified the track duration, artist popularity, genre, available markets,\n",
    "danceability, acousticness, and tempo.  We used the random forest, decision tree, and naive bayes classifiers.\n",
    "The decision tree classifier had the highest accuracy and lowest error rate out of the three classifiers.  In theory the random tree classifier could have been the most efficient if we were able to have a successful run.\n",
    "\n",
    "\n",
    "## Data Analysis:\n",
    "\n",
    "We used the Spotify API with the following objects:\n",
    "- AlbumObject\n",
    "- ArtistObject\n",
    "- AudioFeaturesObject\n",
    "- FollowersObject\n",
    "- TrackObject \n",
    "\n",
    "We are trying to predict the popularity of a random music track given information about the artist, album, and track audio features. The popularity value will be in the same format as Spotify's popularity attribute (the total number of plays the track has).\n",
    "We will use the following attributes:\n",
    "\n",
    "- Track popularity (int: 0-100)\n",
    "    - Discretized to 'Low', \"Below Average', 'Average', 'Above Average', 'High'\n",
    "- Artist popularity (int: 0-100)\n",
    "    - Discretized to 'Low', \"Below Average', 'Average', 'Above Average', 'High'\n",
    "- Genre \n",
    "    - Discretized to 10 of the most popular genres\n",
    "- Danceability (float: 0-1)\n",
    "    - Discretized to 1, 2, 3\n",
    "- Acousticness (float: 0-1)\n",
    "    - Discretized to 1, 2, 3\n",
    "- Duration in ms (int)\n",
    "    - Discretized to 'Short', 'Medium', 'Long'\n",
    "- Tempo (float)\n",
    "    - Discretized to 1, 2, 3\n",
    "- Available Markets\n",
    "    - Discretized to 'Small', 'Medium', 'Large'\n",
    "\n",
    "Data Summary:\n",
    "The popularity values for both tracks and artists were heavily skewed.  Values in the 80s ('Above Average') occured significantly more than any other range. Reflecting on this, we could have used another metric of how well known a track is through how many plays it has and an artist through how many followers they have on their profile.  There didn't seem to be a direct correlation between the artist popularity and the track popularity even though intuitively the relationship makes sense.\n",
    "- Source: https://developer.spotify.com/documentation/web-api/reference/#reference-index\n",
    "    \n",
    "## Classification Results:\n",
    "We used Naive Bayes, Decision tree, and random forest \n",
    "classification in our project. We used these because we thought they would provide the \n",
    "most accurate results. The design and implementation of the Naive bayes and Decision\n",
    "tree were kept very similar from how they were implemented in our PA's while \n",
    "random forest was a new challenge. We used matricies for all of the classifiers to \n",
    "find and display accuracies. In our process, we found that between the Naive Bayes and \n",
    "Decision tree classifiers, Decision trees were more accurate.\n",
    "\tRandom forest is an ensemble classification method that uses a list of optimized\n",
    "decision trees to find a more accurate majority label. This was implemented using\n",
    "a fit and predict model with attributes for the list of accurate trees and an\n",
    "accuracy variable. The process is to create N amount of trees with different\n",
    "instances and attributes and keep M amount of the most accurate of them. Once we have that,\n",
    "we can predict instances by taking the majority vote of all the other trees. Unfortunatelly,\n",
    "The predict wouldn't work well on our data so we do not have a value for accuracy.\n",
    "Because of the nature of the classifier being a more accurate collection of decision trees,\n",
    "we expected it to be more accurate then the decision tree and Naive bayes.\n",
    "- Heroku App Link: http://cpsc322-final.herokuapp.com/\n",
    "    - Link with prediction values: http://cpsc322-final.herokuapp.com/predict?track_duration=long&artist_popularity=5&genre=latin&available_markets=small&danceability=2&acousticness=2&tempo=3\n",
    "    \n",
    "## Conclusion:\n",
    "Our project was a lot of fun to work on and gave us some good insight into future data science projects or careers. Our dataset was faily large and the random nature of our song selection meant we got\n",
    "a large variety of genres and artists. Although we had variety in song selection, our data that we mined was skewed towards popularity of upwards of 80% popularity so most of the instances predicted above average.\n",
    "Testing was also made more difficult due to the amount of data we had and mining the data itself took around 20 min. The classifiers themselves preformed how we expected, although it was hard to troubleshoot some\n",
    "of the more technical problems we had to do the nature of our dataset. Specifically the forest classifier was hard to problem solve because of its scope. If we were to do this project again or continue building \n",
    "on it, we would try different classifiers and ways to increase existing\n",
    "classifier efficiency.\n",
    "The decision tree classifier's accuracy was 86.34% and error rate was 1.45%.  These results are fairly reasonable provided that the attributes did not have a strong relationship.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}